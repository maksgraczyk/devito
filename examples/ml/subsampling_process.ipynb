{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devito set up\n",
    "from abc import ABC, abstractmethod\n",
    "from devito import Operator, Function\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "from devito import Grid, Function, dimensions, Eq, Inc\n",
    "import sympy\n",
    "class Layer(ABC):\n",
    "    def __init__(self, input_data):\n",
    "        self._input_data = input_data\n",
    "        self._R = self._allocate()\n",
    "\n",
    "    @abstractmethod\n",
    "    def _allocate(self) -> Function:\n",
    "        # This method should return a Function object corresponding to\n",
    "        # an output of the layer.\n",
    "        pass\n",
    "\n",
    "    def execute(self) -> (Operator, array):\n",
    "        op = Operator(self.equations())\n",
    "        op.cfunction\n",
    "\n",
    "        return (op, self._R.data)\n",
    "\n",
    "    @abstractmethod\n",
    "    def equations(self) -> list:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plain 2D conv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operator `Kernel` run in 0.01 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tyoe= Max\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_image = torch.randint(0,60,(1,3,3,3))\n",
    "class Subsampling(Layer):\n",
    "    def __init__(self, kernel_size, feature_map, function,\n",
    "                 stride=(1, 1), padding=(0, 0), activation=None,\n",
    "                 bias=0):\n",
    "        # All sizes are expressed as (rows, columns).\n",
    "\n",
    "        self._error_check(kernel_size, feature_map, stride, padding)\n",
    "\n",
    "        self._kernel_size = kernel_size\n",
    "        self._function = function\n",
    "        self._activation = activation\n",
    "        self._bias = bias\n",
    "\n",
    "        self._stride = stride\n",
    "        self._padding = padding\n",
    "\n",
    "        super().__init__(input_data=feature_map)\n",
    "\n",
    "    def _error_check(self, kernel_size, feature_map, stride, padding):\n",
    "        if feature_map is None or len(feature_map) == 0:\n",
    "            raise Exception(\"Feature map must not be empty\")\n",
    "\n",
    "        if kernel_size is None or len(kernel_size) != 2:\n",
    "            raise Exception(\"Kernel size is incorrect\")\n",
    "\n",
    "        if stride is None or len(stride) != 2:\n",
    "            raise Exception(\"Stride is incorrect\")\n",
    "\n",
    "        if stride[0] < 1 or stride[1] < 1:\n",
    "            raise Exception(\"Stride cannot be less than 1\")\n",
    "\n",
    "        if padding is None or len(padding) != 2:\n",
    "            raise Exception(\"Padding is incorrect\")\n",
    "\n",
    "        if padding[0] < 0 or padding[1] < 0:\n",
    "            raise Exception(\"Padding cannot be negative\")\n",
    "\n",
    "        map_height = len(feature_map) + 2 * padding[0]\n",
    "        map_width = len(feature_map[0]) + 2 * padding[1]\n",
    "        kernel_height, kernel_width = kernel_size\n",
    "\n",
    "        if (map_height - kernel_height) % stride[0] != 0 or \\\n",
    "           (map_width - kernel_width) % stride[1] != 0:\n",
    "            raise Exception(\"Stride \" + str(stride) + \" is not \"\n",
    "                            \"compatible with feature map, kernel and padding \"\n",
    "                            \"sizes\")\n",
    "\n",
    "    def _allocate(self):\n",
    "        map_height = len(self._input_data) + 2 * self._padding[0]\n",
    "        map_width = len(self._input_data[0]) + 2 * self._padding[1]\n",
    "        kernel_height, kernel_width = self._kernel_size\n",
    "\n",
    "        gridB = Grid(shape=(map_height, map_width))\n",
    "        B = Function(name='B', grid=gridB, space_order=0)\n",
    "\n",
    "        a, b = dimensions('a b')\n",
    "        gridR = Grid(shape=((map_height - kernel_height + self._stride[0])\n",
    "                            // self._stride[0],\n",
    "                            (map_width - kernel_width + self._stride[1])\n",
    "                            // self._stride[1]),\n",
    "                     dimensions=(a, b))\n",
    "        R = Function(name='R', grid=gridR, space_order=0)\n",
    "\n",
    "        for i in range(self._padding[0], map_height - self._padding[0]):\n",
    "            B.data[i] = \\\n",
    "                np.concatenate(([0] * self._padding[1],\n",
    "                                self._input_data[i - self._padding[0]],\n",
    "                                [0] * self._padding[1]))\n",
    "\n",
    "        self._B = B\n",
    "        return R\n",
    "\n",
    "    def equations(self):\n",
    "        a, b = self._B.dimensions\n",
    "        kernel_height, kernel_width = self._kernel_size\n",
    "\n",
    "        rhs = self._function([self._B[self._stride[0] * a + i,\n",
    "                                      self._stride[1] * b + j]\n",
    "                              for i in range(kernel_height)\n",
    "                              for j in range(kernel_width)]) + self._bias\n",
    "        print(\"tyoe=\",type(rhs))\n",
    "        if self._activation is not None:\n",
    "            rhs = self._activation(rhs)\n",
    "\n",
    "        return [Eq(self._R[a, b], rhs)]\n",
    "                \n",
    "Sample_2D = Subsampling((2,2),single_image[0][0], lambda l: sympy.Max(*l))\n",
    "tup_2d = Sample_2D.execute()\n",
    "tup_2d[0].apply()\n",
    "tup_2d[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Eq(R[x, y], Max(B[x, y], B[x, y + 1], B[x + 1, y], B[x + 1, y + 1]))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample_2D.equations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3d max sampling, only channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid[extent=(1.0, 1.0, 1.0), shape=(3, 2, 2), dimensions=(f, g, h)]\n",
      "type= [Eq(R[0, c, d], Max(B[0, c, d], B[0, c, d + 1], B[0, c + 1, d], B[0, c + 1, d + 1])), Eq(R[1, c, d], Max(B[1, c, d], B[1, c, d + 1], B[1, c + 1, d], B[1, c + 1, d + 1])), Eq(R[2, c, d], Max(B[2, c, d], B[2, c, d + 1], B[2, c + 1, d], B[2, c + 1, d + 1]))]\n",
      "rhs: [Eq(R[0, c, d], Max(B[0, c, d], B[0, c, d + 1], B[0, c + 1, d], B[0, c + 1, d + 1])), Eq(R[1, c, d], Max(B[1, c, d], B[1, c, d + 1], B[1, c + 1, d], B[1, c + 1, d + 1])), Eq(R[2, c, d], Max(B[2, c, d], B[2, c, d + 1], B[2, c + 1, d], B[2, c + 1, d + 1]))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operator `Kernel` run in 0.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 2, 2)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Subsampling(Layer):\n",
    "    def __init__(self, kernel_size, feature_map, function,\n",
    "                 stride=(1, 1), padding=(0, 0), activation=None,\n",
    "                 bias=0):\n",
    "        \n",
    "\n",
    "        self._kernel_size = kernel_size\n",
    "        self._function = function\n",
    "        self._activation = activation\n",
    "        self._bias = bias\n",
    "\n",
    "        self._stride = stride\n",
    "        self._padding = padding\n",
    "\n",
    "        super().__init__(input_data=feature_map)\n",
    "\n",
    "   \n",
    "\n",
    "    def _allocate(self):\n",
    "        map_height = self._input_data.shape[1] + 2 * self._padding[0]\n",
    "        map_width = self._input_data.shape[2] + 2 * self._padding[1]\n",
    "        kernel_height, kernel_width = self._kernel_size\n",
    "        b, c, d = dimensions('b c d')\n",
    "        gridB = Grid(shape=(self._input_data.shape[0], map_height, map_width),\\\n",
    "                    dimensions=(b, c, d))\n",
    "        B = Function(name='B', grid=gridB, space_order=0)\n",
    "\n",
    "        f, g, h = dimensions('f g h')\n",
    "        gridR = Grid(shape=( self._input_data.shape[0],\\\n",
    "                            (map_height - kernel_height + self._stride[0])\n",
    "                            // self._stride[0],\n",
    "                            (map_width - kernel_width + self._stride[1])\n",
    "                            // self._stride[1]),\n",
    "                     dimensions=(f, g, h))\n",
    "        print(gridR)\n",
    "        R = Function(name='R', grid=gridR, space_order=0)\n",
    "        #add padding to start and end of each row\n",
    "        for channel in range(self._input_data.shape[0]):\n",
    "            for i in range(self._padding[0], map_height - self._padding[0]):\n",
    "                B.data[channel, i] = \\\n",
    "                    np.concatenate(([0] * self._padding[1],\n",
    "                                    self._input_data[channel, i - self._padding[0]],\n",
    "                                    [0] * self._padding[1]))\n",
    "\n",
    "        self._B = B\n",
    "        return R\n",
    "    def equations(self):\n",
    "        a, b, c = self._B.dimensions\n",
    "        kernel_height, kernel_width = self._kernel_size\n",
    "        channels = self._input_data.shape[0]\n",
    "        equation_sum = []\n",
    "        for channel in range(channels):\n",
    "            rhs = self._function([self._B[channel, self._stride[0] * b + i,\n",
    "                                      self._stride[1] * c + j]\n",
    "                              for i in range(kernel_height)\n",
    "                              for j in range(kernel_width)])\n",
    "            equation_sum.append(Eq(self._R[channel, b, c], rhs))\n",
    "        print(\"type=\",equation_sum)\n",
    "        print(\"rhs:\", equation_sum)\n",
    "        if self._activation is not None:\n",
    "            rhs = self._activation(rhs)\n",
    "        #print(\"eq:\",Eq(self._R[a, b, c], rhs))\n",
    "        return equation_sum\n",
    "                \n",
    "Sample_2D = Subsampling((2,2),single_image[0], lambda l: sympy.Max(*l))\n",
    "tup_2d = Sample_2D.execute()\n",
    "tup_2d[0].apply()\n",
    "tup_2d[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the convolution in 4D - Naively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/devito/types/grid.py:206: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  spacing = (np.array(self.extent) / (np.array(self.shape) - 1)).astype(self.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid[extent=(1.0, 1.0, 1.0, 1.0), shape=(1, 3, 2, 2), dimensions=(e, f, g, h)]\n",
      "rhs: Max(B[0, 0, c, d], B[0, 0, c, d + 1], B[0, 0, c + 1, d], B[0, 0, c + 1, d + 1], B[0, 1, c, d], B[0, 1, c, d + 1], B[0, 1, c + 1, d], B[0, 1, c + 1, d + 1], B[0, 2, c, d], B[0, 2, c, d + 1], B[0, 2, c + 1, d], B[0, 2, c + 1, d + 1])\n",
      "type: Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operator `Kernel` run in 0.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 3, 2, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Subsampling_4d(Layer):\n",
    "    def __init__(self, kernel_size, feature_map, function,\n",
    "                 stride=(1, 1), padding=(0, 0), activation=None,\n",
    "                 bias=0):\n",
    "        # All sizes are expressed as (rows, columns).\n",
    "\n",
    "        #self._error_check(kernel_size, feature_map, stride, padding)\n",
    "\n",
    "        self._kernel_size = kernel_size\n",
    "        self._function = function\n",
    "        self._activation = activation\n",
    "        self._bias = bias\n",
    "\n",
    "        self._stride = stride\n",
    "        self._padding = padding\n",
    "\n",
    "        super().__init__(input_data=feature_map)\n",
    "\n",
    "\n",
    "    def _allocate(self):\n",
    "        map_height = self._input_data.shape[2] + 2 * self._padding[0]\n",
    "        map_width = self._input_data.shape[3] + 2 * self._padding[1]\n",
    "        kernel_height, kernel_width = self._kernel_size\n",
    "        a, b, c, d = dimensions('a b c d')\n",
    "        gridB = Grid(shape=(self._input_data.shape[0], self._input_data.shape[1], map_height, map_width),\\\n",
    "                    dimensions=(a, b, c, d))\n",
    "        B = Function(name='B', grid=gridB, space_order=0)\n",
    "\n",
    "        e, f, g, h = dimensions('e f g h')\n",
    "        gridR = Grid(shape=( self._input_data.shape[0],  self._input_data.shape[1],\\\n",
    "                            (map_height - kernel_height + self._stride[0])\n",
    "                            // self._stride[0],\n",
    "                            (map_width - kernel_width + self._stride[1])\n",
    "                            // self._stride[1]),\n",
    "                     dimensions=(e, f, g, h))\n",
    "        print(gridR)\n",
    "        R = Function(name='R', grid=gridR, space_order=0)\n",
    "        #add padding to start and end of each row\n",
    "        for image in range(self._input_data.shape[0]):\n",
    "            for channel in range(self._input_data.shape[1]):\n",
    "                for i in range(self._padding[0], map_height - self._padding[0]):\n",
    "                    B.data[image, channel, i] = \\\n",
    "                        np.concatenate(([0] * self._padding[1],\n",
    "                                        self._input_data[image, channel, i - self._padding[0]],\n",
    "                                        [0] * self._padding[1]))\n",
    "\n",
    "        self._B = B\n",
    "        return R\n",
    "\n",
    "    def equations(self):\n",
    "        a, b, c, d = self._B.dimensions\n",
    "        kernel_height, kernel_width = self._kernel_size\n",
    "        images = self._input_data.shape[0]\n",
    "        channels = self._input_data.shape[1] \n",
    "        rhs = self._function([self._B[image, channel, self._stride[0] * c + i,\n",
    "                                      self._stride[1] * d + j]\n",
    "                              for image in range(images)\n",
    "                              for channel in range(channels)\n",
    "                              for i in range(kernel_height)\n",
    "                              for j in range(kernel_width)\n",
    "                              ]) + self._bias\n",
    "\n",
    "        print(\"rhs:\", rhs)\n",
    "        print(\"type:\", type(rhs))\n",
    "        if self._activation is not None:\n",
    "            rhs = self._activation(rhs)\n",
    "\n",
    "        return [Eq(self._R[a, b, c, d], rhs)]\n",
    "\n",
    "Sample_obj4d = Subsampling_4d((2,2),single_image, lambda l: sympy.Max(*l))\n",
    "tup4d = Sample_obj4d.execute()\n",
    "tup4d[0].apply()\n",
    "tup4d[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we are not getting what we expect.\n",
    "The operator should have a Max for each channel and each image.\n",
    "Also in the result, are getting the biggest values across all 3 channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this works howver the loops are in python and not in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_image = torch.randint(0,60,(2,3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class Subsampling_4d with abstract methods execute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-8c8a8d83aa68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mrhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mequation_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mSample_obj4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubsampling_4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;31m#A.equations()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mtup4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSample_obj4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class Subsampling_4d with abstract methods execute"
     ]
    }
   ],
   "source": [
    "class Subsampling_4d(Layer):\n",
    "    def __init__(self, kernel_size, feature_map, function,\n",
    "                 stride=(1, 1), padding=(0, 0), activation=None,\n",
    "                 bias=0):\n",
    "        # All sizes are expressed as (batch, channel, rows, columns).\n",
    "        #error check to be added later\n",
    "        #self._error_check(kernel_size, feature_map, stride, padding)\n",
    "\n",
    "        self._kernel_size = kernel_size\n",
    "        self._function = function\n",
    "        self._activation = activation\n",
    "        self._bias = bias\n",
    "\n",
    "        self._stride = stride\n",
    "        self._padding = padding\n",
    "\n",
    "        super().__init__(input_data=feature_map)\n",
    "\n",
    "\n",
    "    def _allocate(self):\n",
    "        map_height = self._input_data.shape[2] + 2 * self._padding[0]\n",
    "        map_width = self._input_data.shape[3] + 2 * self._padding[1]\n",
    "        kernel_height, kernel_width = self._kernel_size\n",
    "        a, b, c, d = dimensions('a b c d')\n",
    "        gridB = Grid(shape=(self._input_data.shape[0], self._input_data.shape[1], map_height, map_width),\\\n",
    "                    dimensions=(a, b, c, d))\n",
    "        B = Function(name='B', grid=gridB, space_order=0)\n",
    "\n",
    "        e, f, g, h = dimensions('e f g h')\n",
    "        gridR = Grid(shape=( self._input_data.shape[0],  self._input_data.shape[1],\\\n",
    "                            (map_height - kernel_height + self._stride[0])\n",
    "                            // self._stride[0],\n",
    "                            (map_width - kernel_width + self._stride[1])\n",
    "                            // self._stride[1]),\n",
    "                     dimensions=(e, f, g, h))\n",
    "        print(gridR)\n",
    "        R = Function(name='R', grid=gridR, space_order=0)\n",
    "        #add padding to start and end of each row\n",
    "        for image in range(self._input_data.shape[0]):\n",
    "            for channel in range(self._input_data.shape[1]):\n",
    "                for i in range(self._padding[0], map_height - self._padding[0]):\n",
    "                    B.data[image, channel, i] = \\\n",
    "                        np.concatenate(([0] * self._padding[1],\n",
    "                                        self._input_data[image, channel, i - self._padding[0]],\n",
    "                                        [0] * self._padding[1]))\n",
    "\n",
    "        self._B = B\n",
    "        return R\n",
    "\n",
    "    def equations(self):\n",
    "        a, b, c, d = self._B.dimensions\n",
    "        kernel_height, kernel_width = self._kernel_size\n",
    "        images = self._input_data.shape[0]\n",
    "        channels = self._input_data.shape[1]\n",
    "        equation_sum = []\n",
    "        for image in range(images):\n",
    "            for channel in range(channels):\n",
    "                rhs = self._function([self._B[image,channel, self._stride[0] * c + i,\n",
    "                                          self._stride[1] * d + j]\n",
    "                                  for i in range(kernel_height)\n",
    "                                  for j in range(kernel_width)])\n",
    "                equation_sum.append(Eq(self._R[image,channel, c, d], rhs))\n",
    "            #equation_sum.append(Eq(self._R[image,0,channel, b, c], rhs))\n",
    "        if self._activation is not None:\n",
    "            rhs = self._activation(rhs)\n",
    "        return equation_sum\n",
    "Sample_obj4 = Subsampling_4d((2,2),batch_image, lambda l: sympy.Max(*l))\n",
    "#A.equations()\n",
    "tup4 = Sample_obj4.execute()\n",
    "tup4[0].apply()\n",
    "tup4[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define _POSIX_C_SOURCE 200809L\n",
      "#include \"stdlib.h\"\n",
      "#include \"math.h\"\n",
      "#include \"sys/time.h\"\n",
      "#include \"xmmintrin.h\"\n",
      "#include \"pmmintrin.h\"\n",
      "#include \"omp.h\"\n",
      "\n",
      "struct dataobj\n",
      "{\n",
      "  void *restrict data;\n",
      "  int * size;\n",
      "  int * npsize;\n",
      "  int * dsize;\n",
      "  int * hsize;\n",
      "  int * hofs;\n",
      "  int * oofs;\n",
      "} ;\n",
      "\n",
      "struct profiler\n",
      "{\n",
      "  double section0;\n",
      "} ;\n",
      "\n",
      "\n",
      "int Kernel(struct dataobj *restrict B_vec, struct dataobj *restrict R_vec, const int c_M, const int c_m, const int d_M, const int d_m, struct profiler * timers)\n",
      "{\n",
      "  float (*restrict B)[B_vec->size[1]][B_vec->size[2]][B_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[B_vec->size[1]][B_vec->size[2]][B_vec->size[3]]) B_vec->data;\n",
      "  float (*restrict R)[R_vec->size[1]][R_vec->size[2]][R_vec->size[3]] __attribute__ ((aligned (64))) = (float (*)[R_vec->size[1]][R_vec->size[2]][R_vec->size[3]]) R_vec->data;\n",
      "\n",
      "  /* Flush denormal numbers to zero in hardware */\n",
      "  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_ON);\n",
      "  _MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);\n",
      "  struct timeval start_section0, end_section0;\n",
      "  gettimeofday(&start_section0, NULL);\n",
      "  /* Begin section0 */\n",
      "  for (int c = c_m; c <= c_M; c += 1)\n",
      "  {\n",
      "    for (int d = d_m; d <= d_M; d += 1)\n",
      "    {\n",
      "      R[0][0][c][d] = fmax(B[0][0][c][d], fmax(B[0][0][c][d + 1], fmax(B[0][0][c + 1][d], B[0][0][c + 1][d + 1])));\n",
      "      R[0][1][c][d] = fmax(B[0][1][c][d], fmax(B[0][1][c][d + 1], fmax(B[0][1][c + 1][d], B[0][1][c + 1][d + 1])));\n",
      "      R[0][2][c][d] = fmax(B[0][2][c][d], fmax(B[0][2][c][d + 1], fmax(B[0][2][c + 1][d], B[0][2][c + 1][d + 1])));\n",
      "      R[1][0][c][d] = fmax(B[1][0][c][d], fmax(B[1][0][c][d + 1], fmax(B[1][0][c + 1][d], B[1][0][c + 1][d + 1])));\n",
      "      R[1][1][c][d] = fmax(B[1][1][c][d], fmax(B[1][1][c][d + 1], fmax(B[1][1][c + 1][d], B[1][1][c + 1][d + 1])));\n",
      "      R[1][2][c][d] = fmax(B[1][2][c][d], fmax(B[1][2][c][d + 1], fmax(B[1][2][c + 1][d], B[1][2][c + 1][d + 1])));\n",
      "    }\n",
      "  }\n",
      "  /* End section0 */\n",
      "  gettimeofday(&end_section0, NULL);\n",
      "  timers->section0 += (double)(end_section0.tv_sec-start_section0.tv_sec)+(double)(end_section0.tv_usec-start_section0.tv_usec)/1000000;\n",
      "  return 0;\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tup4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data([[[[48., 48.],\n",
       "        [52., 57.]],\n",
       "\n",
       "       [[31., 33.],\n",
       "        [50., 50.]],\n",
       "\n",
       "       [[22., 36.],\n",
       "        [28., 36.]]],\n",
       "\n",
       "\n",
       "      [[[51., 51.],\n",
       "        [51., 51.]],\n",
       "\n",
       "       [[51., 51.],\n",
       "        [51., 51.]],\n",
       "\n",
       "       [[59., 59.],\n",
       "        [48., 44.]]]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tup4[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7, 10, 28],\n",
       "          [41, 48, 47],\n",
       "          [52, 40, 57]],\n",
       "\n",
       "         [[31, 21, 27],\n",
       "          [16,  6, 33],\n",
       "          [46, 50,  3]],\n",
       "\n",
       "         [[14, 22,  1],\n",
       "          [12, 11, 36],\n",
       "          [23, 28, 16]]],\n",
       "\n",
       "\n",
       "        [[[41, 16, 43],\n",
       "          [46, 51, 46],\n",
       "          [17, 17,  1]],\n",
       "\n",
       "         [[ 0, 45, 42],\n",
       "          [45, 51, 26],\n",
       "          [35, 22,  9]],\n",
       "\n",
       "         [[30, 59,  3],\n",
       "          [22, 16, 44],\n",
       "          [48, 28, 17]]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing it the inefficent way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operator `Kernel` run in 0.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample_2D = Subsampling((2,2),single_image[0][0], lambda l: sympy.Max(*l))\n",
    "tup_2d = Sample_2D.execute()\n",
    "tup_2d[0].apply()\n",
    "tup_2d[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operator `Kernel` run in 0.01 s\n",
      "Operator `Kernel` run in 0.01 s\n",
      "Operator `Kernel` run in 0.01 s\n"
     ]
    }
   ],
   "source": [
    "results_tensor = torch.ones(1,3,2,2)\n",
    "for channel in range(single_image.shape[1]):\n",
    "    Sample_2D_channel = Subsampling((2,2),single_image[0][channel], lambda l: sympy.Max(*l))\n",
    "    tup_2d = Sample_2D_channel.execute()\n",
    "    tup_2d[0].apply()\n",
    "    results_tensor[0][channel] = torch.from_numpy(tup_2d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[59., 55.],\n",
       "          [59., 55.]],\n",
       "\n",
       "         [[32., 32.],\n",
       "          [59., 58.]],\n",
       "\n",
       "         [[54., 31.],\n",
       "          [54., 22.]]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works but we have to call the opperator as many times as the channels and the images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
